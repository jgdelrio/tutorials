{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to train a model for image recognition is finding images that belong to the desired class (or classes).\n",
    "\n",
    "We will use for this task the **ImageNet** dataset. This is the dataset of the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) which is a popular challenge that has brought many important innovations. ImageNet currently has 14,197,122 images with 21841 synsets indexed (see [Imagenet](http://www.image-net.org/)).\n",
    "\n",
    "ImageNet aims to provide on average 1k images to illustrate each one of their 100k synsets, the majority of the synsets are nouns (80.000+). The **synsets** (synonym sets) come from WordNet which is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept.\n",
    "\n",
    "More information about ImageNet can be found here: http://www.image-net.org/about-overview\n",
    "\n",
    "More information about WordNet can be found here: https://wordnet.princeton.edu/\n",
    "These useful classified images can be obtained using Python with the following steps:\n",
    "\n",
    "\n",
    "### ImageNet\n",
    "\n",
    "This dataset is publicly available which the goal of promoting the development of computer vision methods. It includes 1M images and 1k different object classes.\n",
    "Typical challenges performed in this dataset include:\n",
    "\n",
    "- Image classification: Predict the classes of objects present.\n",
    "- Object localization: Image classification (and draw a bounding box around one example of each object present).\n",
    "- Object detection: Image classification (and draw a bounding box around each object present).\n",
    "- Labeling videos.\n",
    "\n",
    "During the first five years the pace of improvements have been dramatic, with great success using CNNs and the papers published have become a must read.\n",
    "\n",
    "<img src=\"./fig/ILSVRC_improvements.png\" alt=\"RGB explination\" width=\"500\"/>\n",
    "\n",
    "\n",
    "Some of the techniques applied to improve the accuracy of the predictions include:\n",
    "\n",
    "#### Basics:\n",
    "* CNNs: Convolutional Neural Networks\n",
    "* ReLUS: Neurons with nonlinearity as Rectified Linear Units as they train faster than for example tanh units and they do not require input normalization to prevent saturation, although local normalization still helps generalization. Response normalization helps to reduce the final error.\n",
    "\n",
    "#### Reducing Overfitting:\n",
    "* Data Augmentation: \n",
    "    - Applying transformations (translation, rotations, zooming...) having the dataset multiplied by factors of 2048.\n",
    "    - PCA performed on the RGB values, altering the intensities of the channels and adding to each image multiples of the principal componenets found with magnitues proportional to the corresponding eigenvalues itmes a random variables (from a Gaussian with mean 0 and st dev 01)\n",
    "* Dropout: Combining predictions of many models is very effective to reduce errors but it's way too expensive for big neural networks that take days to train. Dropouts sets to zero the output of each hidden node with a probability of 0.5 and this way the drop out neurons do not contribute to the forward pass nor they participate on the back-propagation. So every time the NN presents a different architecture but all of them share weights. This technique reduces co-adaptations of neurons as they cannot rely on the presence of other particular neurons and they are forced to learn more robust features.\n",
    "\n",
    "#### Details:\n",
    "- Stochastic gradient descent for training with batches of 128, momentum of 0.9 and weight decay of 0.0005 which was not merely a regularizer but it reduces as well the training error.\n",
    "- The initialization was done with a Gaussian distribution with st. dev. 0.01\n",
    "- The learning rate at 0.01 and reduced three times prior to termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.3\n",
      "IPython 7.8.0\n",
      "\n",
      "numpy 1.17.2\n",
      "pandas 0.25.1\n",
      "sklearn 0.21.3\n",
      "cv2 3.4.7\n",
      "\n",
      "compiler   : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 19.0.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : ba32e6742de096f4d2f8f37f15230974390412b7\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,pandas,sklearn,cv2 -g\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [ImageNet: A Large-Scale Hierarchical Image Database](https://ieeexplore.ieee.org/document/5206848), 2009.\n",
    "\n",
    "[2] [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks), 2012.\n",
    "\n",
    "[3] [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901), 2013.\n",
    "\n",
    "[4] [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842), 2014.\n",
    "\n",
    "[5] [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556), 2015.\n",
    "\n",
    "[6] [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385), 2015.\n",
    "\n",
    "[7] [ImageNet Large Scale Visual Recognition Challenge](https://link.springer.com/article/10.1007/s11263-015-0816-y), 2015.\n",
    "\n",
    "[8] [Image Classification transfer learning with Inception v3](https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/index.html#0)\n",
    "\n",
    "[9] [Advanced Guide to Inception v3 on Cloud TPU](https://cloud.google.com/tpu/docs/inception-v3-advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
